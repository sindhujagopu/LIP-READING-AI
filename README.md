# LIP READING-AI
Welcome to the LIP READING-AI repository! This project focuses on developing an artificial intelligence system capable of reading lips from video inputs. Leveraging state-of-the-art machine learning techniques and deep learning models, our system aims to improve communication accessibility, particularly for the hearing-impaired community.

## Features
* Deep Learning Models: Utilizes advanced neural networks for accurate lip reading.
* Video Processing: Efficient video preprocessing and feature extraction.
* Pre-trained Models: Includes pre-trained models for immediate use.
* Custom Training: Provides tools for training models on custom datasets.
* Extensive Documentation: Comprehensive guides and tutorials for setup, usage, and customization.

## Getting Started
### Prerequisites
* Python 3.7+
* TensorFlow 2.x
* OpenCV
* Other dependencies listed in requirements.txt

### Dataset and pre-trained model

* You can download the dataset and the pretrained model from here ðŸ‘‡
* Dataset Link: https://drive.google.com/drive/folders/1zPIXGsSnC7NTh4E40a2QwdpNa-1FRn3A?usp=sharing
* Pre-Trained Model: https://drive.google.com/file/d/1u7ClC7z99SC4X9azEGG4zZhJkpkoYtlY/view?usp=sharing

### Installation
Clone the repository and install the required dependencies:

In bash:
* Copy code -> git clone https://github.com/Mabhusubhani001/LIP-READING-AI.git
* cd LIP-READING-AI
* pip install -r requirements.txt

## Model Archietecture(Sample)

<img width="586" alt="Screenshot 2024-06-09 at 3 23 11 PM" src="https://github.com/Mabhusubhani001/LIP-READING-AI/assets/139627113/815b6dd3-42c5-4716-91de-17a368f870cd">

## Usage

* Facilitates communication in masked situations by focusing on visible lip movements for speech interpretation, helping both the hearing-impaired and deaf.
* Augments surveillance systems by interpreting silent video footage to understand conversations without audio.
* Aids in monitoring sensitive areas by reading lips from video feeds where audio is unclear or unavailable.
* Enhances virtual assistants and customer service systems by incorporating lip-reading capabilities for better user interaction, especially for the deaf.
* Supports language learners and individuals in speech therapy, including deaf people, by demonstrating the formation of words on lips.
* Assists law enforcement in decoding silent video footage to gather crucial evidence from lip movements.
* Improves user experience in media consumption by providing subtitles based on lip reading in noisy environments.
* and a lot more ...

## Acknowledgments
We would like to thank the contributors and the open-source community for their valuable work and support.
